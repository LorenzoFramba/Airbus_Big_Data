{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import isnan, when, count, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"2004.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_spark():\n",
    "    spark = SparkSession.builder.appName(\"Project\").getOrCreate()\n",
    "    sc = spark.sparkContext\n",
    "    return spark, sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark, sc = _init_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Year: int, Month: int, DayofMonth: int, DayOfWeek: int, DepTime: string, CRSDepTime: int, ArrTime: string, CRSArrTime: int, UniqueCarrier: string, FlightNum: int, TailNum: string, ActualElapsedTime: string, CRSElapsedTime: int, AirTime: string, ArrDelay: string, DepDelay: string, Origin: string, Dest: string, Distance: int, TaxiIn: int, TaxiOut: int, Cancelled: int, CancellationCode: string, Diverted: int, CarrierDelay: int, WeatherDelay: int, NASDelay: int, SecurityDelay: int, LateAircraftDelay: int]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "df = sqlContext.read.load(filename, \n",
    "                      format='com.databricks.spark.csv', \n",
    "                      header='true',\n",
    "                      delimiter=',',\n",
    "                      inferSchema='true')\n",
    "df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing as is stated in the task along with the 'Year'\n",
    "col_to_drop = ['ArrTime', 'ActualElapsedTime', 'AirTime', 'TaxiIn', 'Diverted', \n",
    "               'CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay', 'Year']\n",
    "df = df.drop(*col_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_amount = df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"CancelationCode\" has too much \"null\" (98% of the data) we will remove it too. Others have no missing values except for \"TailNum\", that has only 127 values left.  \n",
    "df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deletion of the \"CancelationCode\" and droping rows that contain \"TailNum\"\n",
    "df = df.drop('CancellationCode')\n",
    "df = df.filter(df.TailNum.isNotNull() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of data saved dropping rows with null in the \"TailNum\" column\n",
    "df.count()/previous_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"ArrDelay\" and \"DepDelay\" have string type. We cast them to Integer\n",
    "df = df.withColumn(\"ArrDelay\", df[\"ArrDelay\"].cast(IntegerType()))\n",
    "df = df.withColumn(\"DepDelay\", df[\"DepDelay\"].cast(IntegerType()))\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df.select([x[0] for x in df.dtypes if 'int' in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I guess it is too pythonic and we nees to change it's PEARSON CORRELATION\n",
    "\n",
    "[df.corr(\"ArrDelay\", c[0]) for c in corr_matrix.dtypes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NON_corr_matrix = df.select([x[0] for x in df.dtypes if x[1] !='int']).show(5)\n",
    "NON_corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to visualize data, it has to be transformed in Pandas\n",
    "#unfortunately, our dataset is too large, therefore we only have to get a sample\n",
    "# in this case we only get 25% of our data, with no replacement\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "dfPanda = df.sample(False, 0.25, 42).toPandas()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I will be using Altair for visualization, which accepts only 5000 max observations\n",
    "#from here we can tell what airports have the longest trips\n",
    "\n",
    "import altair as alt\n",
    "\n",
    "dfPanda = dfPanda.sample(n=5000, random_state=1)\n",
    "alt.Chart(dfPanda).mark_point().encode(\n",
    "    x='Distance',\n",
    "    y='Origin',\n",
    "    color='DayOfWeek',\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
